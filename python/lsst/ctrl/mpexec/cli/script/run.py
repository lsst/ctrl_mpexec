# This file is part of ctrl_mpexec.
#
# Developed for the LSST Data Management System.
# This product includes software developed by the LSST Project
# (http://www.lsst.org).
# See the COPYRIGHT file at the top-level directory of this distribution
# for details of code ownership.
#
# This software is dual licensed under the GNU General Public License and also
# under a 3-clause BSD license. Recipients may choose which of these licenses
# to use; please see the files gpl-3.0.txt and/or bsd_license.txt,
# respectively.  If you choose the GPL option then the following text applies
# (but note that there is still no warranty even if you opt for BSD instead):
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import annotations

from collections.abc import Iterable
from typing import TYPE_CHECKING, Literal

import astropy.units as u

import lsst.utils.timer
from lsst.pipe.base import ExecutionResources, QuantumGraph, TaskFactory
from lsst.pipe.base.mp_graph_executor import MPGraphExecutor
from lsst.pipe.base.single_quantum_executor import SingleQuantumExecutor
from lsst.resources import ResourcePath, ResourcePathExpression
from lsst.utils.doImport import doImportType
from lsst.utils.iteration import ensure_iterable
from lsst.utils.logging import getLogger
from lsst.utils.threads import disable_implicit_threading

from ..butler_factory import ButlerFactory
from ..utils import MP_TIMEOUT

if TYPE_CHECKING:
    from lsst.pipe.base.execution_graph_fixup import ExecutionGraphFixup

_LOG = getLogger(__name__)


def run(
    qg: QuantumGraph,
    *,
    task_factory: TaskFactory | None = None,
    pdb: str | None,
    graph_fixup: str,
    init_only: bool,
    no_versions: bool,
    processes: int,
    start_method: Literal["spawn", "forkserver"] | None,
    profile: str,
    register_dataset_types: bool,
    skip_init_writes: bool,
    timeout: int | None,
    butler_config: ResourcePathExpression,
    input: Iterable[str] | str,
    output: str | None,
    output_run: str | None,
    extend_run: bool,
    replace_run: bool,
    prune_replaced: str | None,
    data_query: str | None,
    skip_existing_in: Iterable[str] | None,
    skip_existing: bool,
    debug: bool,
    fail_fast: bool,
    clobber_outputs: bool,
    summary: ResourcePathExpression | None,
    enable_implicit_threading: bool,
    cores_per_quantum: int,
    memory_per_quantum: str | None,
    rebase: bool,
    raise_on_partial_outputs: bool,
    **kwargs: object,
) -> None:
    """Implement the command line interface `pipetask run` subcommand.

    Should only be called by command line tools and unit test code that test
    this function.

    Parameters
    ----------
    qg : `lsst.pipe.base.QuantumGraph`
        A QuantumGraph generated by a previous subcommand.
    task_factory : `lsst.pipe.base.TaskFactory`, optional
        A custom task factory to use.
    pdb : `str`, optional
        Debugger to import and use (via the ``post_mortem`` function) in the
        event of an exception.
    graph_fixup : `str`
        The name of the class or factory method which makes an instance used
        for execution graph fixup.
    init_only : `bool`
        If true, do not actually run; just register dataset types and/or save
        init outputs.
    no_versions : `bool`
        If true, do not save or check package versions.
    processes : `int`
        The number of processes to use.
    start_method : `str` or `None`
        Start method from `multiprocessing` module, `None` selects the best
        one for current platform.
    profile : `str`
        File name to dump cProfile information to.
    register_dataset_types : `bool`
        If true, register DatasetTypes that do not already exist in the
        Registry.
    skip_init_writes : `bool`
        If true, do not write collection-wide 'init output' datasets (e.g.
        schemas).
    timeout : `int`
        Timeout for multiprocessing; maximum wall time (sec).
    butler_config : convertible to `lsst.resources.ResourcePath`
        Path to butler repository configuration.
    input : `~collections.abc.Iterable` [ `str` ] or `None`
        List of names of the input collection(s).
    output : `str` or `None`
        Name of the output CHAINED collection. This may either be an existing
        CHAINED collection to use as both input and output (if `input` is
        `None`), or a new CHAINED collection created to include all inputs
        (if `input` is not `None`). In both cases, the collection's children
        will start with an output RUN collection that directly holds all new
        datasets (see `output_run`).
    output_run : `str` or `None`
        Name of the new output RUN collection. If not provided then `output`
        must be provided and a new RUN collection will be created by appending
        a timestamp to the value passed with `output`. If this collection
        already exists then `extend_run` must be passed.
    extend_run : `bool`
        Instead of creating a new RUN collection, insert datasets into either
        the one given by `output_run` (if provided) or the first child
        collection of `output` (which must be of type RUN).
    replace_run : `bool`
        Before creating a new RUN collection in an existing CHAINED collection,
        remove the first child collection (which must be of type RUN). This can
        be used to repeatedly write to the same (parent) collection during
        development, but it does not delete the datasets associated with the
        replaced run unless `prune-replaced` is also True. Requires `output`,
        and `extend_run` must be `None`.
    prune_replaced : `str` or `None`
        If not `None`, delete the datasets in the collection replaced by
        `replace_run`, either just from the datastore ("unstore") or by
        removing them and the RUN completely ("purge"). Requires
        ``replace_run`` to be `True`.
    data_query : `str`
        User query selection expression.
    skip_existing_in : `~collections.abc.Iterable` [ `str` ] or `None`
        Accepts list of collections, if all Quantum outputs already exist in
        the specified list of collections then that Quantum will be excluded
        from the QuantumGraph.
    skip_existing : `bool`
        Appends output RUN collection to the ``skip_existing_in`` list.
    debug : `bool`
        If true, enable debugging output using lsstDebug facility (imports
        debug.py).
    fail_fast : `bool`
        If true then stop processing at first error, otherwise process as many
        tasks as possible.
    clobber_outputs : `bool`
        Remove outputs from previous execution of the same quantum before new
        execution.  Only applies to failed quanta if skip_existing is also
        given.
    summary : `str`
        File path to store job report in JSON format.
    enable_implicit_threading : `bool`, optional
        If `True`, do not disable implicit threading by third-party libraries.
        Implicit threading is always disabled during actual quantum execution
        if ``processes > 1``.
    cores_per_quantum : `int`
        Number of cores that can be used by each quantum.
    memory_per_quantum : `str`
        Amount of memory that each quantum can be allowed to use. Empty string
        implies no limit. The string can be either a single integer (implying
        units of MB) or a combination of number and unit.
    rebase : `bool`
        If `True` then reset output collection chain if it is inconsistent with
        the ``inputs``.
    raise_on_partial_outputs : `bool`
        Consider partial outputs an error instead of a success.
    **kwargs : `object`
        Ignored; click commands may accept options for more than one script
        function and pass all the option kwargs to each of the script functions
        which ignore these unused kwargs.
    """
    # Fork option still exists for compatibility but we use spawn instead.
    if start_method == "fork":  # type: ignore[comparison-overlap]
        start_method = "spawn"  # type: ignore[unreachable]
        _LOG.warning("Option --start-method=fork is unsafe and no longer supported, using spawn instead.")

    if not enable_implicit_threading:
        disable_implicit_threading()

    skip_existing_in = tuple(skip_existing_in) if skip_existing_in is not None else ()
    if data_query is None:
        data_query = ""
    inputs = list(ensure_iterable(input)) if input else []
    del input
    enable_lsst_debug = debug
    del debug

    # If we have no output run specified, use the one from the graph rather
    # than letting a new timestamped run be created.
    if not output_run and qg.metadata and (output_run := qg.metadata.get("output_run")):
        output_run = output_run

    # Check that output run defined on command line is consistent with
    # quantum graph.
    if output_run and qg.metadata:
        graph_output_run = qg.metadata.get("output_run", output_run)
        if graph_output_run != output_run:
            raise ValueError(
                f"Output run defined on command line ({output_run}) has to be "
                f"identical to graph metadata ({graph_output_run}). "
                "To update graph metadata run `pipetask update-graph-run` command."
            )

    # Make sure that --extend-run always enables --skip-existing,
    # clobbering should be disabled if --extend-run is not specified.
    if extend_run:
        skip_existing = True
    else:
        clobber_outputs = False

    # Make butler instance. QuantumGraph should have an output run defined,
    # but we ignore it here and let command line decide actual output run.
    butler = ButlerFactory.make_write_butler(
        butler_config,
        qg.pipeline_graph,
        output=output,
        output_run=output_run,
        inputs=inputs,
        extend_run=extend_run,
        rebase=rebase,
        replace_run=replace_run,
        prune_replaced=prune_replaced,
    )

    assert butler.run is not None, "Guaranteed by make_write_butler."
    if skip_existing:
        skip_existing_in += (butler.run,)

    # Enable lsstDebug debugging. Note that this is done once in the
    # main process before PreExecInit and it is also repeated before
    # running each task in SingleQuantumExecutor (which may not be
    # needed if `multiprocessing` always uses fork start method).
    if enable_lsst_debug:
        try:
            _LOG.debug("Will try to import debug.py")
            import debug  # type: ignore  # noqa: F401
        except ImportError:
            _LOG.warning("No 'debug' module found.")

    # Save all InitOutputs, configs, etc.
    if register_dataset_types:
        qg.pipeline_graph.register_dataset_types(butler, include_packages=not no_versions)
    if not skip_init_writes:
        qg.write_init_outputs(butler, skip_existing=skip_existing)
        qg.write_configs(butler, compare_existing=extend_run)
        if not no_versions:
            qg.write_packages(butler, compare_existing=extend_run)

    if init_only:
        return

    if task_factory is None:
        task_factory = TaskFactory()
    resources = ExecutionResources(
        num_cores=cores_per_quantum, max_mem=memory_per_quantum, default_mem_units=u.MB
    )
    quantum_executor = SingleQuantumExecutor(
        butler=butler,
        task_factory=task_factory,
        skip_existing_in=skip_existing_in,
        clobber_outputs=clobber_outputs,
        enable_lsst_debug=enable_lsst_debug,
        resources=resources,
        raise_on_partial_outputs=raise_on_partial_outputs,
    )

    if timeout is None:
        timeout = MP_TIMEOUT
    executor = MPGraphExecutor(
        num_proc=processes,
        timeout=timeout,
        start_method=start_method,
        quantum_executor=quantum_executor,
        fail_fast=fail_fast,
        pdb=pdb,
        execution_graph_fixup=_import_graph_fixup(graph_fixup),
    )
    # Have to reset connection pool to avoid sharing connections with
    # forked processes.
    butler.registry.resetConnectionPool()
    try:
        with lsst.utils.timer.profile(profile, _LOG):
            executor.execute(qg)
    finally:
        if summary:
            report = executor.getReport()
            if report:
                with ResourcePath(summary).open("w") as out:
                    # Do not save fields that are not set.
                    out.write(report.model_dump_json(exclude_none=True, indent=2))


def _import_graph_fixup(graph_fixup: str) -> ExecutionGraphFixup | None:
    """Import/instantiate graph fixup object.

    Parameters
    ----------
    graph_fixup : `str`
        Graph fixup command-line argument.

    Returns
    -------
    fixup : `ExecutionGraphFixup` or `None`
        Object that imposes additional ordering constraints on the graph.

    Raises
    ------
    ValueError
        Raised if import fails, method call raises exception, or returned
        instance has unexpected type.
    """
    from lsst.pipe.base.execution_graph_fixup import ExecutionGraphFixup

    if graph_fixup:
        try:
            factory = doImportType(graph_fixup)
        except Exception as exc:
            raise ValueError("Failed to import graph fixup class/method") from exc
        try:
            fixup = factory()
        except Exception as exc:
            raise ValueError("Failed to make instance of graph fixup") from exc
        if not isinstance(fixup, ExecutionGraphFixup):
            raise ValueError("Graph fixup is not an instance of ExecutionGraphFixup class")
        return fixup
    return None
